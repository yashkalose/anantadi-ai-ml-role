{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Assignment: Ad Image Insertion in Video with Occlusion Handling***"
      ],
      "metadata": {
        "id": "MwpX1nTdCD44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "88lZAp90CONt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC9dW22xBrV7"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "MDDhtaIwButR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The necessary libraries imported are:*\n",
        "\n",
        "`cv2` for computer vision tasks<br>\n",
        "`numpy` for numerical computations"
      ],
      "metadata": {
        "id": "bRy87vZjCRSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Necessary Files**"
      ],
      "metadata": {
        "id": "Xfn0htN7CUqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = \"advertisement image.jpg\"\n",
        "video = \"input video.mp4\"\n",
        "foreground_path = \"advertisement image.jpg\"\n",
        "foreground = cv2.imread(foreground_path)\n",
        "cap = cv2.VideoCapture('input video.mp4')"
      ],
      "metadata": {
        "id": "K3YLA8N4Bup6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extraction Of Object From Image**"
      ],
      "metadata": {
        "id": "R91vB1aXCXj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image\n",
        "image = cv2.imread(image)  # Replace with the path to your image\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# Perform thresholding to create a binary mask (adjust threshold values as needed)\n",
        "_, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Apply the mask to the original image to extract the object\n",
        "extracted_object = cv2.bitwise_and(image, image, mask=thresh)\n",
        "\n",
        "# Display the original image and the extracted object using Matplotlib\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "axes[0].imshow(image)\n",
        "axes[0].set_title('Original Image')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(extracted_object)\n",
        "axes[1].set_title('Extracted Object')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Get the resolution of the image\n",
        "height, width, channels = image.shape\n",
        "\n",
        "print(f\"Image Resolution: Width = {width}, Height = {height}, Channels = {channels}\")"
      ],
      "metadata": {
        "id": "L0N-d__yBum4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the foreground image is loaded successfully\n",
        "if foreground is None:\n",
        "    print(\"Error: Unable to load the foreground image.\")\n",
        "else:\n",
        "    # Open the video file (change 'input_video2.mp4' to your video file name)\n",
        "    cap = cv2.VideoCapture('input video.mp4')\n",
        "\n",
        "    # Check if the video file is opened successfully\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Unable to open the video file.\")\n",
        "    else:\n",
        "        # Get the original dimensions of the video\n",
        "        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        # Set the desired dimensions for the resized video\n",
        "        output_width = 640  # Set your desired width\n",
        "        output_height = 480  # Set your desired height\n",
        "\n",
        "        # Create VideoWriter object to write the output video\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "        out = cv2.VideoWriter('output_video.avi', fourcc, 20.0, (output_width, output_height))\n",
        "\n",
        "        # Set initial value of weights\n",
        "        alpha = 0.4\n",
        "\n",
        "        while True:\n",
        "            # read the background\n",
        "            ret, background = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                break  # Break the loop if we reach the end of the video\n",
        "\n",
        "\n",
        "\n",
        "            # Resize the foreground image to match the dimensions of the region in the background\n",
        "            foreground_resized = cv2.resize(foreground, (200, 200))\n",
        "\n",
        "            # Select the region in the background where we want to add the image and add the images using cv2.addWeighted()\n",
        "            added_image = cv2.addWeighted(\n",
        "                background[original_height-300:original_height-100, original_width-300:original_width-100, :],\n",
        "                alpha,\n",
        "                foreground_resized,\n",
        "                1 - alpha,\n",
        "                0\n",
        "            )\n",
        "\n",
        "\n",
        "            # Change the region with the result\n",
        "            background[original_height-300:original_height-100, original_width-300:original_width-100] = added_image\n",
        "\n",
        "            # Resize the output frame to fit the desired dimensions\n",
        "            output_frame = cv2.resize(background, (output_width, output_height))\n",
        "\n",
        "            # Write the frame to the output video file\n",
        "            out.write(output_frame)\n",
        "\n",
        "            # For displaying the current value of alpha(weights)\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            cv2.putText(output_frame, 'Press \"a\" to increase alpha, \"d\" to decrease alpha, \"q\" to quit', (10, 30),\n",
        "                        font, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "            cv2.putText(output_frame, 'Current alpha: {{{{{{{{:.2f}}}}}}}}'.format(alpha), (10, 60),\n",
        "                        font, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "            cv2_imshow(output_frame)\n",
        "\n",
        "            k = cv2.waitKey(10)  # Wait for 10 milliseconds\n",
        "\n",
        "            # Press q to break\n",
        "            if k == ord('q'):\n",
        "                break\n",
        "\n",
        "            # Press a to increase alpha by 0.1\n",
        "            elif k == ord('a'):\n",
        "                alpha += 0.1\n",
        "                if alpha >= 1.0:\n",
        "                    alpha = 1.0\n",
        "\n",
        "            # Press d to decrease alpha by 0.1\n",
        "            elif k == ord('d'):\n",
        "                alpha -= 0.1\n",
        "                if alpha <= 0.0:\n",
        "                    alpha = 0.0\n",
        "\n",
        "# Release the video file and destroy all windows\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "_pg4V4dUBukB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "2qO4ScQNBuhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Application Of The Cascade library for graceful Occlusion handling**"
      ],
      "metadata": {
        "id": "Qe3-7faECkyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_hand(video_path, output_path, base_hand_level=0.3, image_scale=0.7):\n",
        "\n",
        "    haar_cascade_path = os.path.abspath('haarcascade_hand.xml')\n",
        "\n",
        "    hand_cascade = cv2.CascadeClassifier(haar_cascade_path)\n",
        "\n",
        "    top_left_y = 600\n",
        "    top_left_x = 120\n",
        "\n",
        "    # Get video properties\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Define VideoWriter\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = video.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert the frame to grayscale for hand detection\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect hands using the cascade classifier\n",
        "        hands = hand_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "        if len(hands) > 0:\n",
        "            # Assuming only one hand is detected, take the first hand\n",
        "            x, y, w, h = hands[0]\n",
        "\n",
        "            # Check if the hand is above a certain level\n",
        "            if y < base_hand_level * height:\n",
        "                # Move the image when the hand is above the specified level\n",
        "                top_left_y = max(0, y - int(image_scale * height))\n",
        "\n",
        "\n",
        "            resized_image = cv2.resize(image, (int(image_scale * w), int(image_scale * h)))\n",
        "\n",
        "\n",
        "            alpha_channel = cv2.resize(resized_image[:, :, 2], (resized_image.shape[1], resized_image.shape[0])) / 255.0\n",
        "            frame[top_left_y:top_left_y + resized_image.shape[0], top_left_x:top_left_x + resized_image.shape[1]] = (\n",
        "                    (1 - alpha_channel)[:, :, np.newaxis] * frame[top_left_y:top_left_y + resized_image.shape[0], top_left_x:top_left_x + resized_image.shape[1]]\n",
        "                    + alpha_channel[:, :, np.newaxis] * resized_image[:, :, :3]\n",
        "            )\n",
        "\n",
        "        out_writer.write(frame)\n",
        "\n",
        "        cv2_imshow( frame)\n",
        "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    video.release()\n",
        "    out_writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "video_path = \"input video.mp4\"\n",
        "output_path = \"output_video_with_logo.mp4\"\n",
        "\n",
        "detect_hand(video_path, output_path)\n"
      ],
      "metadata": {
        "id": "bjUuokOoBueD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}